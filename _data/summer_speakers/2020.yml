# Template for adding speakers
#- filename:
#  poster:
#  name: 
#  personal_site: 
#  img:
#  date: 
#  venue:
#  time: 
#  title: 
#  bio:
#  abstract:

- filename: sambaran-bandyopadhyay
  poster: /assets/img/club_photos/SSS-2020-06.pdf
  name: Sambaran Bandyopadhyay
  personal_site: ~
  img: /assets/img/club_photos/s_bandyopadhyay.png
  date: June 26, 2020
  venue: Zoom Video Call - <a href="http://mailman.cs.utah.edu/mailman/listinfo/ucds-seminar" target="_blank" style="text-decoration:underline;">Subscribe to our Mailing List</a> to receive the link via email
  time: 12:00 pm
  title: Graph Representation Learning in the Presence of Outliers
  bio: >
    Sambaran Bandyopadhyay is an Advisory Research Engineer at IBM Research, India. He is also a final year PhD student at the department of Computer Science and Automation at Indian Institute of Science, Bangalore. Sambaran has published his research works in top tier AI conferences such as AAAI, IJCAI, KDD, WSDM, ICAPS, ECAI etc. and also has 8 patents filed to USPTO. He has been a member of the technical program committee of several AI conferences such as NeurIPS, ICML, AAAI, ECML-PKDD, etc.
  abstract: >
    Graph representation learning has received significant interest in the machine learning community. Different types of algorithms such as skip-gram based optimization, matrix factorization, deep-autoencoders and more recently, graph neural networks are proposed in the literature. Analysis of outliers in a graph is important as all real-life networks contain outlier nodes. A (community) outlier in a graph is a node which violets the overall community structure of the graph. Recent studies have shown that outlier nodes can affect the embeddings of other regular nodes in a graph. Further, their embeddings can get mixed easily with other regular nodes, which makes it difficult to detect them by post-processing. So, it is important to reduce the effect of outlier nodes on the embeddings of other nodes in a graph and detect them in an integrated way.<br><br>
    In this talk, we will characterize different types of outliers present in an attributed graph. We discuss some recent approaches which integrate outlier detection and network embedding into a single framework, and hence minimize the effect of outliers on the embeddings of regular nodes in a graph. We would also present a set of experimental results to motivate the problem and to show the usefulness of such integrated approaches.


- filename: ayan-mukhopadhyay
  poster: /assets/img/club_photos/SSS-2020-05.pdf
  name: Ayan Mukhopadhyay
  personal_site: ~
  img: /assets/img/club_photos/a_mukhopadhyay.jpg
  date: June 19, 2020
  venue: Zoom Video Call - <a href="http://mailman.cs.utah.edu/mailman/listinfo/ucds-seminar" target="_blank" style="text-decoration:underline;">Subscribe to our Mailing List</a> to receive the link via email
  time: 11:30 am
  title: Robust Incident Forecasting and Response
  bio: >
    Ayan Mukhopadhyay is a Post-Doctoral Research Fellow at the Stanford Intelligent Systems Lab at Stanford University, USA. His research interests include multi-agent systems, robust machine learning and decision-making under uncertainty. He was awarded the 2019 CARS post-doctoral fellowship by the Center of Automotive Research at Stanford (CARS). Before joining Stanford, he finished his PhD at Vanderbilt University’s Computational Economics Research Lab. His doctoral thesis was nominated for the Victor Lesser Distinguished Dissertation Award 2020. His work on urban emergency response management has been covered in the Government Technology Magazine, Financial Times, multiple global smart city summits, and received a best paper award at ICLR’s AI for Social Good Workshop.
  abstract: >
    Emergency response to spatial-temporal incidents like crimes and accidents is a major challenge in today’s world. This talk will focus on two problems in this context. In the first segment, we will look at how robust machine learning models can help combat crimes like illegal poaching. While there are a variety of incident prediction models available to identify spatial-temporal patterns in such incidents, they fail to take attacker evasion into account. Specifically, poachers can shift their spatial preferences for committing crimes by observing patrols. This talk will present a general framework that models the interaction between off-the-shelf machine learning algorithms and attackers as a Stackelberg game. We will look at how such a game model works and how it can be solved to design patrol strategies. In the second segment, the talk will focus on how creating decentralized multi-agent approaches can improve emergency response in urban areas.

- filename: arpita-biswas
  poster: /assets/img/club_photos/SSS-2020-04.pdf
  name: Arpita Biswas
  personal_site: https://sites.google.com/view/arpitabiswas/
  img: /assets/img/club_photos/a_biswas.jpg
  date: June 12, 2020
  venue: Zoom Video Call - <a href="http://mailman.cs.utah.edu/mailman/listinfo/ucds-seminar" target="_blank" style="text-decoration:underline;">Subscribe to our Mailing List</a> to receive the link via email
  time: 11:30 am
  title: Two-Sided Fairness Guarantees for Recommendation Systems (<a href="https://arxiv.org/pdf/2002.10764.pdf" target = "_blank" style="text-decoration:underline;">arXiv</a>)
  bio: >
    Arpita Biswas is a Google Ph.D. Fellow at the Department of Computer Science and Automation, Indian Institute of Science. Her broad areas of interest include Game Theory, Optimization, and Machine Learning. She is presently looking at problems in Computational Social Choice Theory and Fairness in Machine Learning. Prior to her Ph.D., she worked as a Research Engineer at Xerox Research Centre India. Her work spans several research spaces such as multi-agent learning, incentive mechanisms, facility location, planning and scheduling, etc. Thus far, she has worked on problems arising from real-world scenarios like online crowd-sourcing, resource allocation, dynamic pricing in transportation, and ride-sharing. More details about her can be obtained at <a href href="https://sites.google.com/view/arpitabiswas/" target="_blank">https://sites.google.com/view/arpitabiswas/</a>.
  abstract: >
    Major B2C eCommerce websites (such as Amazon, Spotify, Swiggy) can be thought of as two-sided platforms, with customers on one side and producers on the other. Traditionally, recommendation protocols of these platforms are customer-centric---focusing on maximizing  customer satisfaction by tailoring the recommendation according to the personalized preferences of individual customers. However, this may lead to unfair distribution of exposure among the producers and adversely impact their well-being. As more and more people depend on such platforms to earn a living, it is important to strike a balance between fairness among the producers and customer satisfaction. The problem of two-sided fairness in recommendation can be formulated as a matroid constrained fair allocation problem. This problem naturally captures a number of other resource-allocation applications, including budgeted course allocation, graph partition, and allocation of cloud computing resources. Our main contribution is to develop polynomial time algorithms for fair allocation of indivisible items (with formal guarantees on fairness and feasibility) in several practical scenarios which can be formulated as matroid constrained problems.<br><br>
    In this talk, I’ll start by motivating the problem and then defining some popular fairness notions. Next, I’ll discuss the matroid constrained fair allocation problem, and show how the solutions can be applied to ensure two-sided fair recommendation. I’ll conclude by listing down some open problems.

- filename: eunice-jun
  poster: /assets/img/club_photos/SSS-2020-03.pdf
  name: Eunice Jun
  personal_site: https://homes.cs.washington.edu/~emjun/
  img: /assets/img/club_photos/e_jun.png
  date: May 29, 2020
  venue: Zoom Video Call - <a href="http://mailman.cs.utah.edu/mailman/listinfo/ucds-seminar" target="_blank" style="text-decoration:underline;">Subscribe to our Mailing List</a> to receive the link via email
  time: 12:00 pm
  title: "Tea: A High-level Language and Runtime System for Automating Statistical Analysis"
  bio: >
    Eunice Jun is a PhD student in the Paul G. Allen School of Computer Science & Engineering at the University of Washington. Her research focuses on developing new tools and methods for conducting valid and reproducible statistical analyses. She hopes to make conducting valid data analyses easy (and fun) for end-users. She incorporates methods and techniques from human-computer interaction, programming languages, software engineering, and data science. Her work has been supported by a UW CSE Wilma Bradley Fellowship and an NSF Graduate Research Fellowship.
  abstract: >
    Current statistical tools place the burden of valid, reproducible statistical analyses on the user. Users must have deep knowledge of statistics to not only identify their research questions, hypotheses, and domain assumptions but also select valid statistical tests for their hypotheses. As quantitative data become increasingly available in all disciplines, data analysis will continue to become a common task for people who may not have statistical expertise. Tea, a high-level declarative language for automating statistical test selection and execution, abstracts the details of analyses from users, empowering them to perform valid analyses by expressing their goals and domain knowledge. In this talk, I will discuss the design and implementation of Tea, lessons learned through the process, and other related ongoing work at the University of Washington. *<b>The talk is designed to be friendly for a non-technical audience with many opportunities for technical, conceptual, and other research-related questions.</b>*

- filename: anirbit-mukherjee
  poster: /assets/img/club_photos/SSS-2020-02.pdf
  name: Anirbit Mukherjee
  personal_site: https://sites.google.com/view/anirbit/home
  img: /assets/img/club_photos/a_mukherjee.jpg
  date: May 21, 2020
  venue: Zoom Video Call - <a href="http://mailman.cs.utah.edu/mailman/listinfo/ucds-seminar" target="_blank" style="text-decoration:underline;">Subscribe to our Mailing List</a> to receive the link via email
  time: 12:00 pm
  title: Understanding training of depth 2 nets under minimal distributional assumptions and data poisoning attacks
  bio: >
    Anirbit, is a (final) year Ph.D. student in applied mathematics at the Johns Hopkins University advised by Prof. Amitabh Basu. He specializes in deep-learning theory and has been awarded 2 fellowships from JHU for this research, "Walter L.Robb Fellowship" and the inaugural "Mathematical Institute for Data Science Fellowship." Earlier, he was a researcher in Quantum Field Theory, while doing his undergrad in physics at the Chennai Mathematical Institute (CMI) and masters in theoretical physics at the Tata Institute of Fundamental Research (TIFR). For more details, you can visit his <a href="https://sites.google.com/view/anirbit/home" target="_blank">website</a>.
  abstract: >
    The question of provable training of neural nets is mathematically extremely challenging and vastly open. Over the last year, we have investigated certain special cases at depth 2 and have given provable guarantees in regimes hitherto unexplored. Our results probe the particularly challenging trifecta of having finitely large nets, while not tying the data to any specific distribution and while having an adversarial attack.
    <br><br>
    We will try to cover 3 of our results in this talk : (a) analysis of a simple stochastic algorithm which near-optimally provably trains a single ReLU gate in the realizable setting as well as under a data poisoning attack using only mild distributional assumptions, (b) showing that noise assisted gradient descent on a ReLU gate can be proven to be "diffusive" in nature without having to make any distributional assumptions beyond realizability and lastly (c) we demonstrate a class of iterative non-gradient algorithms ("Neuro-Tron") which can train a class of "singe filter" depth 2 nets under a data poisoning attack on true realizable labels s.t the error in the recovered weights scales inversely with the width above a certain finite threshold. This provably brings to light the advantage of having a large width when defending against an adversarial attack.
    <br><br>
    This talk will is based on our recently released two part series of works,
    <ul>
    <li>Part 1: <a href="https://arxiv.org/abs/2005.01699" target="_blank">https://arxiv.org/abs/2005.01699</a></li>
    <li>Part 2: <a href="https://arxiv.org/abs/2005.04211" target="_blank">https://arxiv.org/abs/2005.04211</a></li>
    </ul>
  
- filename: nitish-gupta
  poster: ~
  name: Nitish Gupta
  personal_site: https://nitishgupta.github.io/
  img: /assets/img/club_photos/n_gupta.png
  date: May 14, 2020
  venue: Zoom Video Call - <a href="http://mailman.cs.utah.edu/mailman/listinfo/ucds-seminar" target="_blank" style="text-decoration:underline;">Subscribe to our Mailing List</a> to receive the link via email
  time: 12:00 pm
  title: Neural Module Networks for Reasoning over Text
  bio: >
    Nitish is a senior PhD student in Computer Science at the University of Pennsylvania pursuing research in NLP. He is advised by Prof. Dan Roth and co-advised by Prof. Sameer Singh, UCI. Nitish's research focuses on developing structured models for grounded language understanding, primarily in the context of making machines understand and answer questions against text. He is particularly interested in models that perform reasoning by understanding the compositional nature of language, and are able to provide a formal semantic parse and an explanation about their predictions. For more details you can visit <a href="https://nitishgupta.github.io/" target="_blank">https://nitishgupta.github.io/</a>.
  abstract: >
    Answering compositional questions that require multiple steps of reasoning against text is challenging, especially when they involve discrete, symbolic operations. In this talk, I will outline the challenges in learning these models for non-synthetic questions on open-domain text, where a model needs to deal with the diversity of natural language and perform a broad range of reasoning. I will present our interpretable and modular neuro-symbolic approach based on neural module networks (NMNs) and show how we extend NMNs by: (a) introducing modules that reason over a paragraph of text, performing symbolic reasoning over numbers and dates in a probabilistic and differentiable manner; and (b) proposing unsupervised auxiliary loss to help learning. In conclusion, I will present our recent work on methods for achieving faithfull interpretations in such compositional models and challenges for future research.
